dat <- read.csv( "tic-tac-toe.data", header=FALSE)
names(dat) <-
c( 'TL', 'TM', 'TR', 'ML', 'MM', 'MR', 'BL', 'BM', 'BR', 'outcome')
set.seed(31415)
wh <- sample.int( nrow(dat), nrow(dat) * .70)
train <- dat[ sample(wh, replace=TRUE), c('TL', 'MM', 'outcome')]
rownames(train) <- NULL
test <- dat[ sample(-wh, replace=TRUE), c('TL', 'MM', 'outcome')]
rownames(test) <- NULL
file="data.RData"
save( test, train, file=file)
set.seed(31415)
file="data.RData"
load(file)
library(caret)
library()
ctrl <- trainControl(method = "repeatedcv", repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary
)
fit <- train( outcome ~ ., data=train, method="glm", family = "binomial", trControl = ctrl)
library(pRoc)
install.packages('pROC')
library(pRoc)
library(pROC)
ctrl <- trainControl(method = "repeatedcv", repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary
)
fit <- train( outcome ~ ., data=train, method="glm", family = "binomial", trControl = ctrl)
fit
summary(fit)
library(ml.plus)
install.packages('ml.plus')
library(ml.plus)
fit$finalModel
table( observed=test$outcome, predicted=predict(fit,test) )
attach(test)
tab <- tab
tab <- table( observed=test$outcome, predicted=predict(fit,test) )
attach(test)
tab <- tab
test$outcome <- as.numeric(as.character(test$outcome))
outcome <- as.numeric((as.character(outcome)))
tpr <- function(x,y) sum(x==y & x ) /sum(x)
fpr <- function(x,y) sum(x!=y & !x) /sum(!x)
tnr <- function(x,y) sum(y==x & !x) /sum(!x)
fnr <- function(x,y) sum(x!=y & x ) /sum(x)
test$outcome <- as.numeric(as.character(test$outcome))
outcome <- as.numeric((as.character(outcome)))
sum(test$outcome)/nrow(test)                        # prevalence
( accuracy = sum(diag(tab))/sum(tab) )      # accuracy
1- accuracy                                 # error rate
sum( outcome == fit.class & outcome )/sum(outcome) # TPR
detach(test)
tpr(test$outcome,test$fit.class)
tnr(test$outcome,test$fit.class)  # Specificity
fpr(test$outcome,test$fit.class)# 0.5414365
fnr(test$outcome,test$fit.class)#0.1823204
```
library(shiny)
runApp("C:/Users/Sandhya/Documents/shiny")
runApp("C:/Users/Sandhya/Documents/shiny")
rm(list=ls())
library("twitteR")
library("ROAuth")
library(base64enc)
consumer_key = "4JTnQWS4GTjiAUMAip9cOOgTN"
consumer_secret = "YrvhqyjBqisvPY3rPYKJDbsj51ZwDMCVMv5xQabuE5uPu7qCaS"
access_token <- "113685444-c9IyRYDFjzT3aWVQHfIurw2BKfR2YNX79TsNBkBP"
access_secret <- "rW0S53xj24z1dHZAq5hLEEApeQ09si0nhIdolQxtNYvoN"
cred <- setup_twitter_oauth(consumer_key, consumer_secret, access_token = NULL , access_secret= NULL)
cred <- setup_twitter_oauth(consumer_key, consumer_secret, access_token  , access_secret)
twitt <- searchTwitter("#yoyo", n=1500)
twitt
rm(list=ls())
library("twitteR")
library("ROAuth")
library(base64enc)
consumer_key = "4JTnQWS4GTjiAUMAip9cOOgTN"
consumer_secret = "YrvhqyjBqisvPY3rPYKJDbsj51ZwDMCVMv5xQabuE5uPu7qCaS"
access_token <- "113685444-c9IyRYDFjzT3aWVQHfIurw2BKfR2YNX79TsNBkBP"
access_secret <- "rW0S53xj24z1dHZAq5hLEEApeQ09si0nhIdolQxtNYvoN"
cred <- setup_twitter_oauth(consumer_key, consumer_secret, access_token  , access_secret)
save(cred ,file="credentials.RData")
library(shiny)
library(twitteR)
library(base64enc)
runApp("C:/Users/Sandhya/Documents/shiny")
runApp("C:/Users/Sandhya/Documents/shiny")
runApp("C:/Users/Sandhya/Documents/shiny")
library("twitteR")
library("ROAuth")
library(base64enc)
consumer_key = "4JTnQWS4GTjiAUMAip9cOOgTN"
consumer_secret = "YrvhqyjBqisvPY3rPYKJDbsj51ZwDMCVMv5xQabuE5uPu7qCaS"
access_token <- "113685444-c9IyRYDFjzT3aWVQHfIurw2BKfR2YNX79TsNBkBP"
access_secret <- "rW0S53xj24z1dHZAq5hLEEApeQ09si0nhIdolQxtNYvoN"
cred <- setup_twitter_oauth(consumer_key, consumer_secret, access_token  , access_secret)
save(cred ,file="credentials.RData")
getwd()
setwd("C:\\Users\\Sandhya\\Documents\\shiny")
library("twitteR")
library("ROAuth")
library(base64enc)
consumer_key = "4JTnQWS4GTjiAUMAip9cOOgTN"
consumer_secret = "YrvhqyjBqisvPY3rPYKJDbsj51ZwDMCVMv5xQabuE5uPu7qCaS"
access_token <- "113685444-c9IyRYDFjzT3aWVQHfIurw2BKfR2YNX79TsNBkBP"
access_secret <- "rW0S53xj24z1dHZAq5hLEEApeQ09si0nhIdolQxtNYvoN"
cred <- setup_twitter_oauth(consumer_key, consumer_secret, access_token  , access_secret)
save(cred ,file="credentials.RData")
runApp("C:/Users/Sandhya/Documents/shiny")
runApp("C:/Users/Sandhya/Documents/shiny")
runApp("C:/Users/Sandhya/Documents/shiny")
setwd("C:\\Users\\Sandhya\\Documents\\shiny_1")
getwd()
library("twitteR")
library("ROAuth")
library(base64enc)
consumer_key = "4JTnQWS4GTjiAUMAip9cOOgTN"
consumer_secret = "YrvhqyjBqisvPY3rPYKJDbsj51ZwDMCVMv5xQabuE5uPu7qCaS"
access_token <- "113685444-c9IyRYDFjzT3aWVQHfIurw2BKfR2YNX79TsNBkBP"
access_secret <- "rW0S53xj24z1dHZAq5hLEEApeQ09si0nhIdolQxtNYvoN"
cred <- setup_twitter_oauth(consumer_key, consumer_secret, access_token  , access_secret)
save(cred ,file="credentials.RData")
library(shiny)
library(twitteR)
runApp("C:/Users/Sandhya/Documents/shiny")
runApp("C:/Users/Sandhya/Documents/shiny")
removeCustomeWords <- function (virginAmericacomplete) {
for(i in 1:length(virginAmericacomplete)){
virginAmericacomplete[i] <- tryCatch({
virginAmericacomplete[i] =  removeWords(virginAmericacomplete[i], c(stopwords("english")))
virginAmericacomplete[i]
}, error=function(cond) {
virginAmericacomplete[i]
}, warning=function(cond) {
virginAmericacomplete[i]
})
}
return(virginAmericacomplete)
}
removeCustomeWords(virginAmericacomplete)
library('devtools')
library(tm) # Framework for text mining.
library(SnowballC) # Provides wordStem() for stemming.
library(ggplot2) # Plot word frequencies.
library(scales) # Include commas in numbers.
library(Rgraphviz) # Correlation plots
library(wordcloud) # routines to create word cloud
library(rpart)  # cart models
library(RWeka)  # R wrappers for weka tools
library(ROCR)   # model performance routines
library(pROC)   # model performance routines
library('MASS')
library('devtools')
library(sentiment) # sentiments
library(twitteR) # twitter
library(plyr)
library(RColorBrewer) # color plots
library(e1071) # naive bayes
library(RTextTools) # accuracy measure
library(Rstem)
dat <- read.csv("bigdata.csv", sep = ",", header = T,  row.names=NULL, stringsAsFactors = FALSE)
source("cleanuptweets.R")
virginAmericatweets <- sapply(dat$text,function(x) gettext(x))
virginAmericacomplete <- sapply(virginAmericatweetscleaned,cleanTweetsAndRemoveNAs )
virginAmericatweetscleaned <- sapply(virginAmericatweets, cleanTweets)
dat <- read.csv("bigdata.csv", sep = ",", header = T,  row.names=NULL, stringsAsFactors = FALSE)
dat <- read.csv("c:\\Users\\Sandhya\\Documents\\bigdata.csv", sep = ",", header = T,  row.names=NULL, stringsAsFactors = FALSE)
source("cleanuptweets.R")
virginAmericatweets <- sapply(dat$text,function(x) gettext(x))
virginAmericatweetscleaned <- sapply(virginAmericatweets, cleanTweets)
virginAmericacomplete <- sapply(virginAmericatweetscleaned,cleanTweetsAndRemoveNAs )
removeCustomeWords(virginAmericacomplete)
getWordCloud <- function (txtdataframe , inText , emotion ) {
emos = levels(factor(final_result.df$emotion))
n_emos = length(emos)
emo.docs = rep("", n_emos)
txtTweets = removeCustomeWords(txtTweets)
for (i in 1:n_emos){
emo.docs[i] = paste(txtTweets[emotion == emos[i]], collapse=" ")
}
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
require(wordcloud)
suppressWarnings(comparison.cloud(tdm, colors = brewer.pal(n_emos, "Dark2"),  scale = c(3,.5), random.order = FALSE, title.size = 1.5))
}
getWordCloud(final_result.df,txtTweets,emotion)
emoveCustomeWords <- function (inText) {
for(i in 1:length(inText)){
inText[i] <- tryCatch({
inText[i] =  removeWords(inText[i], c(stopwords("english")))
inText[i]
}, error=function(cond) {
inText[i]
}, warning=function(cond) {
inText[i]
})
}
return(inText)
}
getWordCloud <- function (txtdataframe , inText , emotion ) {
emos = levels(factor(txtdataframe$emotion))
n_emos = length(emos)
emo.docs = rep("", n_emos)
txtTweets = removeCustomeWords(inText)
for (i in 1:n_emos){
emo.docs[i] = paste(txtTweets[emotion == emos[i]], collapse=" ")
}
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
require(wordcloud)
suppressWarnings(comparison.cloud(tdm, colors = brewer.pal(n_emos, "Dark2"),  scale = c(3,.5), random.order = FALSE, title.size = 1.5))
}
getWordCloud(final_result.df,txtTweets,emotion)
output$word_cloud <- renderImage({
getWordCloud(final_result.df,txtTweets,emotion)
output$word_cloud <- renderImage({
getWordCloud(final_result.df,txtTweets,emotion)
})
library(shiny)
shinyUI(fluidPage(
titlePanel("Twitter Sentiment Analysis"),
sidebarLayout(
sidebarPanel(
textInput("searchTerm", label = "Enter twitter search keywords below", value = "#VirginAmerica"),
selectInput('plot_opt', 'Plot options', c('emotion', 'polarity'), selectize=TRUE),
submitButton("Update View")
),
mainPanel(plotOutput("plot_emotion"))
)
))
library(shiny)
shinyUI(fluidPage(
titlePanel("Twitter Sentiment Analysis"),
sidebarLayout(
sidebarPanel(
textInput("searchTerm", label = "Enter twitter search keywords below", value = "#VirginAmerica"),
selectInput('plot_opt', 'Plot options', c('emotion', 'polarity'), selectize=TRUE),
submitButton("Update View")
),
mainPanel(plotOutput("plot_emotion"))
)
))
getWordCloud(VirginAmericaSentiment.df,virginAmericacomplete,Virginemotion)
VirginAmericaSentiment.df = within(VirginAmericaSentiment.df, emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
VirginAmericaSentiment.df = data.frame(text=virginAmericacomplete, emotion=Virginemotion, polarity=VirginPol, stringsAsFactors=FALSE)
library('devtools')
library(tm) # Framework for text mining.
library(SnowballC) # Provides wordStem() for stemming.
library(ggplot2) # Plot word frequencies.
library(scales) # Include commas in numbers.
library(Rgraphviz) # Correlation plots
library(wordcloud) # routines to create word cloud
library(rpart)  # cart models
library(RWeka)  # R wrappers for weka tools
library(ROCR)   # model performance routines
library(pROC)   # model performance routines
library('MASS')
library('devtools')
library(sentiment) # sentiments
library(twitteR) # twitter
library(plyr)
library(RColorBrewer) # color plots
library(e1071) # naive bayes
library(RTextTools) # accuracy measure
library(Rstem)
dat <- read.csv("c:\\Users\\Sandhya\\Documents\\bigdata.csv", sep = ",", header = T,  row.names=NULL, stringsAsFactors = FALSE)
virginAmericatweets <- sapply(dat$text,function(x) gettext(x))
virginAmericatweetscleaned <- sapply(virginAmericatweets, cleanTweets)
virginAmericacomplete <- sapply(virginAmericatweetscleaned,cleanTweetsAndRemoveNAs )
scoreresult <- score.sentiment(virginAmericacomplete,pos.words,neg.words)
VirginAmericaemotion = classify_emotion(virginAmericacomplete, algorithm="bayes", prior=1.0)
Virginemotion = VirginAmericaemotion[,7]
Virginemotion[is.na(Virginemotion)] = "unknown"
VirginemotionClassPol <- classify_polarity(virginAmericacomplete,algorithm = "bayes")
VirginPol <- VirginemotionClassPol[,4]
VirginAmericaSentiment.df = data.frame(text=virginAmericacomplete, emotion=Virginemotion, polarity=VirginPol, stringsAsFactors=FALSE)
# rearrange data inside the frame by sorting it
VirginAmericaSentiment.df = within(VirginAmericaSentiment.df, emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
removeCustomeWords <- function (virginAmericacomplete) {
for(i in 1:length(virginAmericacomplete)){
virginAmericacomplete[i] <- tryCatch({
virginAmericacomplete[i] =  removeWords(virginAmericacomplete[i], c(stopwords("english")))
virginAmericacomplete[i]
}, error=function(cond) {
virginAmericacomplete[i]
}, warning=function(cond) {
virginAmericacomplete[i]
})
}
return(virginAmericacomplete)
}
abc <- removeCustomeWords(virginAmericacomplete)
getWordCloud <- function (sentiment_dataframe, virginAmericacomplete, Emotion) {
emos = levels(factor(sentiment_dataframe$emotion))
n_emos = length(emos)
emo.docs = rep("", n_emos)
virginAmericacomplete = removeCustomeWords(virginAmericacomplete)
for (i in 1:n_emos){
emo.docs[i] = paste(virginAmericacomplete[Emotion == emos[i]], collapse=" ")
}
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
require(wordcloud)
suppressWarnings(comparison.cloud(tdm, colors = brewer.pal(n_emos, "Dark2"),  scale = c(3,.5), random.order = FALSE, title.size = 1.5))
}
library(shiny)
library(shiny)
shinyUI(fluidPage(
titlePanel("Twitter Sentiment Analysis"),
sidebarLayout(
sidebarPanel(
textInput("searchTerm", label = "Enter twitter search keywords below", value = "#VirginAmerica"),
selectInput('plot_opt', 'Plot options', c('emotion', 'polarity'), selectize=TRUE),
submitButton("Update View")
),
mainPanel(
tabsetPanel(
tabPanel("Sentiment analysis for the given word ",plotOutput("plot_emotion")),
tabPanel("Word cloud", plotOutput("word_cloud"))
)
)
)
)
))
library(shiny)
library(twitteR)
library(base64enc)
runApp("C:/Users/Sandhya/Documents/shiny")
getwd()
rm(list=ls())
library("twitteR")
library("ROAuth")
library(base64enc)
consumer_key = "4JTnQWS4GTjiAUMAip9cOOgTN"
consumer_secret = "YrvhqyjBqisvPY3rPYKJDbsj51ZwDMCVMv5xQabuE5uPu7qCaS"
access_token <- "113685444-c9IyRYDFjzT3aWVQHfIurw2BKfR2YNX79TsNBkBP"
access_secret <- "rW0S53xj24z1dHZAq5hLEEApeQ09si0nhIdolQxtNYvoN"
cred <- setup_twitter_oauth(consumer_key, consumer_secret, access_token  , access_secret)
save(cred ,file="credentials.RData")
library(shiny)
library(twitteR)
runApp("C:/Users/Sandhya/Documents/shiny")
runApp("C:/Users/Sandhya/Documents/shiny_1")
runApp("C:/Users/Sandhya/Documents/shiny_1")
runApp("C:/Users/Sandhya/Documents/shiny_1")
runApp("C:/Users/Sandhya/Documents/shiny_1")
runApp("C:/Users/Sandhya/Documents/shiny_1")
runApp("C:/Users/Sandhya/Documents/shiny_1")
